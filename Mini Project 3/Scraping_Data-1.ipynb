{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56tfDxbWVq9b"
      },
      "source": [
        "# **Scraping a Site**\n",
        "### Extract links for all countries from the website https://starbucksmenuprices.com/.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTkEIC3CWIvR"
      },
      "source": [
        "## **Step 1: Install Necessary Libraries**\n",
        "Python libraries extend the functionality of Python. Here, we need:\n",
        "*   requests: To fetch the webpage.\n",
        "*   BeautifulSoup (from bs4): To parse and extract data from the HTML.\n",
        "*   **selenium** is used for web automation to scrape exchange rates.\n",
        "*   **pandas** is used to read the consolidated latte prices CSV file.\n",
        "### **Command:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "wf-x5vXBWJLM"
      },
      "outputs": [],
      "source": [
        "# pip install requests beautifulsoup4 pandas selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrNyesRYWegF"
      },
      "source": [
        "## **Step 2: Import Libraries**\n",
        "We start the Python script by importing the libraries we installed. Think of this as unlocking tools we’ll need for our task.\n",
        "*   **import requests**: Enables us to send a request to a webpage.\n",
        "*   **from bs4 import BeautifulSoup**: Allows us to use BeautifulSoup for extracting data.\n",
        "### **Command:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WR3ARXxfWZY_"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import requests  # For fetching the webpage\n",
        "from bs4 import BeautifulSoup  # For parsing the webpage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJU96afEWt9W"
      },
      "source": [
        "## **Step 3: Fetch the Webpage Content**\n",
        "Webpages are made of HTML (a markup language for displaying content). To analyze it, we first need to download the HTML using Python.\n",
        "*  **url = '...'**: This variable stores the URL of the website we want to scrape.\n",
        "*  **requests.get(url)**: Sends a request to the server to get the webpage's content.\n",
        "*   **response.status_code**: Checks the server's response. A code of 200 means the request was successful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8UNA0YZXAxP",
        "outputId": "4b0c701e-a0bc-4835-8b72-9e3478a20b3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully fetched the webpage!\n"
          ]
        }
      ],
      "source": [
        "# URL of the webpage to scrape\n",
        "url = 'https://starbucksmenuprices.com/'\n",
        "\n",
        "# Send a request to the server\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully fetched the webpage!\")\n",
        "else:\n",
        "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awzb8luHdFja"
      },
      "source": [
        "**Common Status Codes:**\n",
        "*   200 OK: The request was successful.\n",
        "*   201 Created: The request has been fulfilled, resulting in the creation of a new resource.\n",
        "*   204 No Content: The server successfully processed the request, but is not returning any content.\n",
        "*   301 Moved Permanently: The requested resource has been permanently moved to a new location.\n",
        "*   302 Found (Temporary Redirect): The requested resource has been temporarily moved to a new location.\n",
        "*   400 Bad Request: The server cannot or will not process the request due to an apparent client error.\n",
        "*   401 Unauthorized: The request requires user authentication.\n",
        "*   403 Forbidden: The server understood the request, but refuses to fulfill it.\n",
        "*   404 Not Found: The server cannot find the requested resource.\n",
        "*   500 Internal Server Error: The server encountered an unexpected condition that prevented it from fulfilling the request.\n",
        "*   503 Service Unavailable: The server is currently unable to handle the request due to a temporary overload or maintenance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Heh1vR1FXUqZ"
      },
      "source": [
        "## **Step 4: Parse the HTML Content**\n",
        "Now that we have the HTML, we need to make it readable for Python using BeautifulSoup.\n",
        "*  **response.text**: The raw HTML text of the webpage.\n",
        "*   **BeautifulSoup(..., 'html.parser')**: Converts the raw HTML into a structured format that Python can easily work with.\n",
        "*   **soup.prettify()**: Prints the HTML in an indented format, making it easier to inspect.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-U2hL-IFX0Jg"
      },
      "outputs": [],
      "source": [
        "# Parse the webpage content with BeautifulSoup\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Print the HTML content to understand its structure\n",
        "# print(soup.prettify())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IdlMyIyX4WT"
      },
      "source": [
        "## **Step 5: Locate the Links**\n",
        "To extract links, inspect the website’s structure using your browser’s developer tools (right-click > \"Inspect\").\n",
        "\n",
        "*   Identify the < a > tags (used for links) within the < ul > list elements.\n",
        "*  **soup.find_all('ul')**: Finds all < ul > (unordered list) elements on the page.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPb3iMD1X0tD",
        "outputId": "5e92e3b6-b018-4ecf-a034-87f0e2d48bdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<ul class=\"sub-menu\">\n",
            "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-32\" id=\"menu-item-32\"><a href=\"https://starbucksmenuprices.com/starbucks-au-prices/\">Australia</a></li>\n",
            "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42\" id=\"menu-item-42\"><a href=\"https://starbucksmenuprices.com/starbucks-brasil-precos/\">Brasil</a></li>\n",
            "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-70\" id=\"menu-item-70\"><a href=\"https://starbucksmenuprices.com/starbucks-%d1%86%d0%b5%d0%bd%d0%b8/\">Bulgaria</a></li>\n",
            "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-58\" id=\"menu-item-58\"><a href=\"https://starbucksmenuprices.com/starbucks-canada-menu/\">Canada</a></li>\n",
            "</ul>\n"
          ]
        }
      ],
      "source": [
        "# Find all <ul> elements containing the country links\n",
        "sections = soup.find_all('ul')  # Locate all <ul> elements\n",
        "\n",
        "# Lists in Python: The result is a list, which can store multiple items.\n",
        "print(sections[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7_XXuejYaDE",
        "outputId": "6886139a-bd5d-4045-d4ac-6415987fdd6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apple banana cherry\n"
          ]
        }
      ],
      "source": [
        "# Example of List:\n",
        "my_list = ['apple', 'banana', 'cherry']\n",
        "print(my_list[0],my_list[1],my_list[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6kLrbMGZgXR"
      },
      "source": [
        "## **Step 6: Extract Links**\n",
        "Now, loop through each < ul > section to find < a > tags (anchors), which represent links.\n",
        "\n",
        "*   **link.text.strip()**: Extracts the text (e.g., \"Australia\") and removes extra spaces.\n",
        "*  **link.get('href')**: Retrieves the URL linked to the < a > tag.\n",
        "*  **country_links.append({...})**: Adds a dictionary with country name and URL to the list.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O6lTXhJVY5jf"
      },
      "outputs": [],
      "source": [
        "# Extract links from the <ul> sections\n",
        "country_links = []  # Empty list to store results\n",
        "\n",
        "for section in sections:\n",
        "    links = section.find_all('a')  # Find all <a> tags in each section\n",
        "    for link in links:\n",
        "        country_name = link.text.strip()  # Get the visible text of the link\n",
        "        country_url = link.get('href')  # Get the href attribute (URL)\n",
        "        country_links.append({'Country': country_name, 'URL': country_url})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7Y1LNOMZ4Cz",
        "outputId": "cfde1e36-cc55-4414-b074-9acfb2c84580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apple\n",
            "banana\n",
            "cherry\n"
          ]
        }
      ],
      "source": [
        "# Example of Loop:\n",
        "for fruit in ['apple', 'banana', 'cherry']:\n",
        "    print(fruit)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZwR1BEIaEMR"
      },
      "source": [
        "## **Step 7: Store Results in a DataFrame**\n",
        "DataFrames are tables provided by the **pandas** library, making it easy to organize and analyze data.\n",
        "*   **pd.DataFrame()**: Converts a list of dictionaries into a tabular format.\n",
        "*   **df.head()**: Displays the first 5 rows.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sagggYqvaAjJ",
        "outputId": "539a2170-5552-463f-effd-e0d00c300f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Country                                                URL\n",
            "0        A-C                                                  #\n",
            "1  Australia  https://starbucksmenuprices.com/starbucks-au-p...\n",
            "2     Brasil  https://starbucksmenuprices.com/starbucks-bras...\n",
            "3   Bulgaria  https://starbucksmenuprices.com/starbucks-%d1%...\n",
            "4     Canada  https://starbucksmenuprices.com/starbucks-cana...\n"
          ]
        }
      ],
      "source": [
        "# Import pandas for working with data\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame\n",
        "df = pd.DataFrame(country_links)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ9B3yLXaYzv"
      },
      "source": [
        "## **Step 8: Save Results to a CSV File**\n",
        "Finally, save the data to a CSV file, which can be opened in Excel or analyzed further.\n",
        "*   **to_csv()**: Exports the DataFrame to a file.\n",
        "*   **index=False**: Prevents saving row numbers in the CSV.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMcQbPTHaRzf",
        "outputId": "b78cbd9d-97cc-4e0b-b15d-eda4e60692e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved country links to starbucks_country_links.csv\n"
          ]
        }
      ],
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('starbucks_country_links.csv', index=False)\n",
        "print(\"Saved country links to starbucks_country_links.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWH-gjY-anPT"
      },
      "source": [
        "## **Complete Script**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTBOre91akMU",
        "outputId": "8df09c4e-0447-4e85-b027-d8f62e2dc631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully fetched the webpage!\n",
            "     Country                                                URL\n",
            "0        A-C                                                  #\n",
            "1  Australia  https://starbucksmenuprices.com/starbucks-au-p...\n",
            "2     Brasil  https://starbucksmenuprices.com/starbucks-bras...\n",
            "3   Bulgaria  https://starbucksmenuprices.com/starbucks-%d1%...\n",
            "4     Canada  https://starbucksmenuprices.com/starbucks-cana...\n",
            "Saved country links to starbucks_country_links.csv\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Fetch the webpage content\n",
        "url = 'https://starbucksmenuprices.com/'\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully fetched the webpage!\")\n",
        "else:\n",
        "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
        "\n",
        "# Step 2: Parse the HTML content\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Step 3: Find all <ul> elements\n",
        "sections = soup.find_all('ul')\n",
        "\n",
        "# Step 4: Extract links\n",
        "country_links = []\n",
        "for section in sections:\n",
        "    links = section.find_all('a')\n",
        "    for link in links:\n",
        "        country_name = link.text.strip()\n",
        "        country_url = link.get('href')\n",
        "        country_links.append({'Country': country_name, 'URL': country_url})\n",
        "\n",
        "# Step 5: Convert to DataFrame\n",
        "df = pd.DataFrame(country_links)\n",
        "print(df.head())  # Display the first 5 rows\n",
        "\n",
        "# Step 6: Save to CSV\n",
        "df.to_csv('starbucks_country_links.csv', index=False)\n",
        "print(\"Saved country links to starbucks_country_links.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LMQgctXbC45"
      },
      "source": [
        "# **Extracting Starbucks Prices Data**\n",
        "### Example of scraping hot coffee price data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeWIMqaAbuPm"
      },
      "source": [
        "## **Step 1: Load the Links**\n",
        "*   **pd.read_csv()**: Reads the CSV file containing country links into a DataFrame.\n",
        "*   **links_file**: The file path of the CSV file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "34R8JoI8bJuf"
      },
      "outputs": [],
      "source": [
        "links_file = 'starbucks_country_links.csv'  # File containing country links\n",
        "country_links = pd.read_csv(links_file)  # Read the CSV file into a DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LVG-1Xub9Iw"
      },
      "source": [
        "## **Step 2: Filter Valid Links**\n",
        "*   **Filter Rows**: ~country_links['URL'].str.contains('#', na=False) excludes rows where the URL contains #.\n",
        "*   **iloc[0]**: Selects the first valid row.\n",
        "*   **Format Country Name**: Converts the country name to lowercase and replaces spaces with hyphens for file naming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UC_gy_nkb8JJ"
      },
      "outputs": [],
      "source": [
        "valid_links = country_links[~country_links['URL'].str.contains('#', na=False)]  # Filter rows without '#'\n",
        "if valid_links.empty:\n",
        "    print(\"No valid links found in the file.\")\n",
        "    exit()\n",
        "\n",
        "first_link = valid_links.iloc[0]  # Select the first valid row\n",
        "country_url = first_link['URL']  # Extract the URL from the first valid row\n",
        "country_name = first_link['Country'].lower().replace(' ', '-')  # Extract and format the country name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtc5vnQ_cknT"
      },
      "source": [
        "## **Step 3: Fetch the Webpage**\n",
        "*   **requests.get(url)**: Fetches the HTML content of the URL.\n",
        "*   **Check Status Code**: Ensures the webpage was successfully fetched (200 status code).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwYfH5dAb3Cv",
        "outputId": "dbb1dcf2-dbdd-4e91-fbba-4bb691d87347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully fetched the page: https://starbucksmenuprices.com/starbucks-au-prices/\n"
          ]
        }
      ],
      "source": [
        "response = requests.get(country_url)\n",
        "if response.status_code == 200:\n",
        "    print(f\"Successfully fetched the page: {country_url}\")\n",
        "else:\n",
        "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0DrR1tjdnZo"
      },
      "source": [
        "## **Step 4: Parse the HTML**\n",
        "*   **BeautifulSoup(..., 'html.parser')**: Parses the HTML content into a structured format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "b7NWyL2McptM"
      },
      "outputs": [],
      "source": [
        "soup = BeautifulSoup(response.text, 'html.parser')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeGYq65neXz_"
      },
      "source": [
        "## **Step 5: Locate \"h2\" Section**\n",
        "*   **Find < h2 > Heading**: Searches for the \"h2\" heading.\n",
        "*   **Find Parent Table**: If the heading is found, locate the parent table containing the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2w5i8SDpeTqS"
      },
      "outputs": [],
      "source": [
        "starbucks_prices_heading = soup.find('h2')  # Locate the \"h2\" section heading\n",
        "if starbucks_prices_heading:\n",
        "    starbucks_prices_table = starbucks_prices_heading.find_parent('table')  # Find the parent table containing the data\n",
        "else:\n",
        "    print(\"'Hot Coffee' section not found on the page.\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS9viHetekWf"
      },
      "source": [
        "## **Step 6: Extract Data**\n",
        "*   **Find Rows**: Selects rows with class item.\n",
        "*  **Extract Columns**: Extracts text from each column and cleans it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "I75UQkcxegiq"
      },
      "outputs": [],
      "source": [
        "starbucks_prices_data = []  # List to store extracted data\n",
        "if starbucks_prices_table:\n",
        "    rows = starbucks_prices_table.find_all('tr', class_='item')  # Find all rows with class \"item\"\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')  # Find all columns in the row\n",
        "        cols = [col.string.strip() for col in cols]  # Clean the text\n",
        "        if cols:  # Skip empty rows\n",
        "            starbucks_prices_data.append(cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44TUK1Lsg2TA"
      },
      "source": [
        "## **Step 7: Save Data**\n",
        "*   **Dynamic File Name**: Includes the country name in the file name.\n",
        "*  **Save to CSV**: Exports the data to a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RZD09uUetEr",
        "outputId": "4ef5f214-595c-4b12-f1a2-8be47482c132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 'Starbucks Prices' prices to starbucks_prices_australia.csv\n",
            "                              Item  Price\n",
            "0                     Banana Bread  $6.30\n",
            "1                 Butter Croissant  $5.78\n",
            "2                 Almond Croissant  $5.78\n",
            "3                Pain Au Chocolate  $5.50\n",
            "4                 Pain Au Chocolat  $6.00\n",
            "..                             ...    ...\n",
            "74               Caramel Macchiato  $6.88\n",
            "75           White Chocolate Mocha  $6.16\n",
            "76                     Caffé Mocha  $6.35\n",
            "77         Caramel Cloud Macchiato  $8.00\n",
            "78  Honeycomb Salted Caramel Latte  $7.30\n",
            "\n",
            "[79 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "if starbucks_prices_data:\n",
        "    df_starbucks_prices= pd.DataFrame(starbucks_prices_data, columns=['Item', 'Price'])  # Create a DataFrame\n",
        "    output_file = f'starbucks_prices_{country_name}.csv'  # Generate file name with country name\n",
        "    df_starbucks_prices.to_csv(output_file, index=False)  # Save to CSV\n",
        "    print(f\"Saved 'Starbucks Prices' prices to {output_file}\")\n",
        "    print(df_starbucks_prices)  # Print the result\n",
        "else:\n",
        "    print(\"No 'Starbucks Prices Data' data found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Complete Script**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QU5qaet1g9kG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully fetched the page: https://starbucksmenuprices.com/starbucks-brasil-precos/\n",
            "Saved 'Starbucks Prices' prices to starbucks_prices_brasil.csv\n",
            "                                     Item    Price\n",
            "0    Frappuccino Apple Crisp - Base Creme  R$22.22\n",
            "1                  Apple Crisp Macchiatto  R$18.90\n",
            "2     Frappuccino Apple Crisp - Base Café  R$22.34\n",
            "3           Apple Crisp Macchiatto Gelado  R$19.01\n",
            "4            Frappuccino Chocolate Branco  R$19.21\n",
            "..                                    ...      ...\n",
            "178     Caneca com Logo lisa branca 355ml  R$47.73\n",
            "179      Caneca com logo lisa preta 355ml  R$47.79\n",
            "180            Caneca do Brasil com 414ml  R$78.95\n",
            "181        Caneca do Rio de Janeiro 414ml  R$79.06\n",
            "182             Caneca de São Paulo 414ml  R$79.29\n",
            "\n",
            "[183 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load the Links\n",
        "links_file = 'starbucks_country_links.csv'  # File containing country links\n",
        "country_links = pd.read_csv(links_file)  # Read the CSV file into a DataFrame\n",
        "\n",
        "# Step 2: Filter Valid Link\n",
        "valid_links = country_links[~country_links['URL'].str.contains('#', na=False)]  # Filter rows without '#'\n",
        "if valid_links.empty:\n",
        "    print(\"No valid links found in the file.\")\n",
        "    exit()\n",
        "\n",
        "first_link = valid_links.iloc[1]  # Select the first valid row\n",
        "country_url = first_link['URL']  # Extract the URL from the first valid row\n",
        "country_name = first_link['Country'].lower().replace(' ', '-')  # Extract and format the country name\n",
        "\n",
        "# Step 3: Fetch the Webpage Content\n",
        "response = requests.get(country_url)\n",
        "if response.status_code == 200:\n",
        "    print(f\"Successfully fetched the page: {country_url}\")\n",
        "else:\n",
        "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
        "    exit()\n",
        "\n",
        "#Step 4: Parse the HTML\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Step 5: Locate \"h2\" Section\n",
        "starbucks_prices_heading = soup.find('h2')  # Locate the \"h2\" section heading\n",
        "if starbucks_prices_heading:\n",
        "    starbucks_prices_table = starbucks_prices_heading.find_parent('table')  # Find the parent table containing the data\n",
        "else:\n",
        "    print(\"'Hot Coffee' section not found on the page.\")\n",
        "    exit()\n",
        "\n",
        "# Step 6: Extract Data\n",
        "starbucks_prices_data = []  # List to store extracted data\n",
        "if starbucks_prices_table:\n",
        "    rows = starbucks_prices_table.find_all('tr', class_='item')  # Find all rows with class \"item\"\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')  # Find all columns in the row\n",
        "        cols = [col.string.strip() for col in cols]  # Clean the text\n",
        "        if cols:  # Skip empty rows\n",
        "            starbucks_prices_data.append(cols)\n",
        "\n",
        "# Step 7: Save Data\n",
        "if starbucks_prices_data:\n",
        "    df_starbucks_prices= pd.DataFrame(starbucks_prices_data, columns=['Item', 'Price'])  # Create a DataFrame\n",
        "    output_file = f'starbucks_prices_{country_name}.csv'  # Generate file name with country name\n",
        "    df_starbucks_prices.to_csv(output_file, index=False)  # Save to CSV\n",
        "    print(f\"Saved 'Starbucks Prices' prices to {output_file}\")\n",
        "    print(df_starbucks_prices)  # Print the result\n",
        "else:\n",
        "    print(\"No 'Starbucks Prices Data' data found.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Consolidating Latte Prices from Country CSV Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 1: Import Libraries**\n",
        "*  **os** is used for interacting with the file system (e.g., listing files in a folder).\n",
        "*  **pandas** is used to read and manipulate CSV files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 2: Define Folder Path**\n",
        "*  Specify the folder where all the country-specific CSV files are located."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder_path = './'  # Adjust to the directory where the files are stored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 3: Initialize Data Storage**\n",
        "*  Create an empty list, **worldwide_latte_prices**, to store the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "worldwide_latte_prices = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 4: Loop Through Files, Read Each File, and Search for \"Latte\":**\n",
        "*  Identify files that match the naming pattern: **starbucks_prices_[country].csv.**\n",
        "*  Extract the country name from the file name.\n",
        "*  Use **pandas** to load the CSV file into a DataFrame.\n",
        "* Iterate through the rows of the DataFrame to find an item containing \"latte\".\n",
        "*  Extract the corresponding price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Loop through files in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    # Check if the file matches the pattern \"starbucks_prices_[country].csv\"\n",
        "    if file_name.startswith('starbucks_prices_') and file_name.endswith('.csv'):\n",
        "        # Extract the country name from the file name\n",
        "        country_name = file_name.replace('starbucks_prices_', '').replace('.csv', '').capitalize()\n",
        "        \n",
        "        # Load the CSV file into a DataFrame\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        df = pd.read_csv(file_path)\n",
        "        \n",
        "        # Step 5: Search for a row containing 'Latte'\n",
        "        for _, row in df.iterrows():\n",
        "            if 'latte' in row['Item'].lower():  # Case-insensitive search for \"latte\"\n",
        "                latte_price = row['Price']\n",
        "                # Append the country name and latte price to the list\n",
        "                worldwide_latte_prices.append({'Country': country_name, 'Latte Price': latte_price})\n",
        "                break  # Stop after finding the first matching \"latte\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 7: Save the Data:**\n",
        "*  onsolidate the extracted data into a new CSV file named **worldwide_latte_prices.csv.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Worldwide latte prices saved to worldwide_latte_prices.csv\n",
            "     Country Latte Price\n",
            "0  Australia       $6.88\n",
            "1     Brasil     R$16.86\n"
          ]
        }
      ],
      "source": [
        "# Save the consolidated data to a new CSV file\n",
        "output_file = 'worldwide_latte_prices.csv'\n",
        "df_worldwide = pd.DataFrame(worldwide_latte_prices)\n",
        "df_worldwide.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Worldwide latte prices saved to {output_file}\")\n",
        "print(df_worldwide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Complete Script**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Worldwide latte prices saved to worldwide_latte_prices.csv\n",
            "     Country Latte Price\n",
            "0  Australia       $6.88\n",
            "1     Brasil     R$16.86\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Define the folder path containing the CSV files\n",
        "folder_path = './'  # Adjust to the directory where the files are stored\n",
        "\n",
        "# Step 2: Initialize a list to store latte prices data\n",
        "worldwide_latte_prices = []\n",
        "\n",
        "# Step 3: Loop through files in the folder\n",
        "for file_name in os.listdir(folder_path):\n",
        "    # Check if the file matches the pattern \"starbucks_prices_[country].csv\"\n",
        "    if file_name.startswith('starbucks_prices_') and file_name.endswith('.csv'):\n",
        "        # Extract the country name from the file name\n",
        "        country_name = file_name.replace('starbucks_prices_', '').replace('.csv', '').capitalize()\n",
        "        \n",
        "        # Load the CSV file into a DataFrame\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        df = pd.read_csv(file_path)\n",
        "        \n",
        "        # Step 4: Search for a row containing 'Latte'\n",
        "        for _, row in df.iterrows():\n",
        "            if 'latte' in row['Item'].lower():  # Case-insensitive search for \"latte\"\n",
        "                latte_price = row['Price']\n",
        "                # Append the country name and latte price to the list\n",
        "                worldwide_latte_prices.append({'Country': country_name, 'Latte Price': latte_price})\n",
        "                break  # Stop after finding the first matching \"latte\"\n",
        "\n",
        "# Step 5: Save the consolidated data to a new CSV file\n",
        "output_file = 'worldwide_latte_prices.csv'\n",
        "df_worldwide = pd.DataFrame(worldwide_latte_prices)\n",
        "df_worldwide.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Worldwide latte prices saved to {output_file}\")\n",
        "print(df_worldwide)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fetch Exchange Rates for Each Country"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 1: Import Libraries:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 2: Load Latte Prices Data:**\n",
        "*  Read the CSV file **worldwide_latte_prices.csv** created by the first script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load country data from the CSV file\n",
        "csv_file = 'worldwide_latte_prices.csv'  # Replace with your CSV file name\n",
        "countries = pd.read_csv(csv_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 3: Set Up Selenium:**\n",
        "*  Initialize the Selenium WebDriver for automated web browsing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up Selenium WebDriver\n",
        "driver = webdriver.Chrome()  # Ensure ChromeDriver is properly set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 4: Define Exchange Rate Function:**\n",
        "*  Create a function to search for exchange rates on DuckDuckGo.\n",
        "*  Open DuckDuckGo, enter the search query, and retrieve the exchange rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to fetch exchange rate using DuckDuckGo\n",
        "def get_exchange_rate_from_duckduckgo(country_name):\n",
        "    try:\n",
        "        # Open DuckDuckGo and search for the exchange rate\n",
        "        driver.get(\"https://duckduckgo.com/\")\n",
        "        search_box = driver.find_element(By.NAME, \"q\")  # Locate search bar\n",
        "        search_box.clear()  # Clear any existing text\n",
        "        search_box.send_keys(f\"{country_name} currency to USD\")  # Enter the search query\n",
        "        search_box.send_keys(Keys.RETURN)  # Press Enter to search\n",
        "\n",
        "        # Wait for results to load\n",
        "        time.sleep(3)\n",
        "\n",
        "        # Locate the input field containing the exchange rate\n",
        "        rate_element = driver.find_element(By.CSS_SELECTOR, 'input[aria-label=\"Currency value in USD\"]')  # Adjusted selector\n",
        "        exchange_rate = rate_element.get_attribute(\"value\")  # Extract the value from the input field\n",
        "        return exchange_rate\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to get exchange rate for {country_name}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 5: Loop Through Countries:**\n",
        "*  For each country in the CSV, fetch the exchange rate using the defined function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching exchange rate for Australia...\n",
            "Fetching exchange rate for Brasil...\n",
            "Failed to get exchange rate for Brasil: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"input[aria-label=\"Currency value in USD\"]\"}\n",
            "  (Session info: chrome=132.0.6834.111); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "0   chromedriver                        0x00000001030267b8 cxxbridge1$str$ptr + 2598452\n",
            "1   chromedriver                        0x000000010301eff8 cxxbridge1$str$ptr + 2567796\n",
            "2   chromedriver                        0x0000000102bbff0c cxxbridge1$string$len + 88260\n",
            "3   chromedriver                        0x0000000102c05000 cxxbridge1$string$len + 371128\n",
            "4   chromedriver                        0x0000000102c3f148 cxxbridge1$string$len + 609024\n",
            "5   chromedriver                        0x0000000102bf8e1c cxxbridge1$string$len + 321492\n",
            "6   chromedriver                        0x0000000102bf9a64 cxxbridge1$string$len + 324636\n",
            "7   chromedriver                        0x0000000102ff16d4 cxxbridge1$str$ptr + 2381136\n",
            "8   chromedriver                        0x0000000102ff49f4 cxxbridge1$str$ptr + 2394224\n",
            "9   chromedriver                        0x0000000102fd803c cxxbridge1$str$ptr + 2277048\n",
            "10  chromedriver                        0x0000000102ff52b4 cxxbridge1$str$ptr + 2396464\n",
            "11  chromedriver                        0x0000000102fc9c04 cxxbridge1$str$ptr + 2218624\n",
            "12  chromedriver                        0x000000010300fd60 cxxbridge1$str$ptr + 2505692\n",
            "13  chromedriver                        0x000000010300fedc cxxbridge1$str$ptr + 2506072\n",
            "14  chromedriver                        0x000000010301ec6c cxxbridge1$str$ptr + 2566888\n",
            "15  libsystem_pthread.dylib             0x0000000184c2df94 _pthread_start + 136\n",
            "16  libsystem_pthread.dylib             0x0000000184c28d34 thread_start + 8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Loop through each country and fetch exchange rates\n",
        "exchange_rates = []\n",
        "for _, row in countries.iterrows():\n",
        "    country_name = row['Country']\n",
        "    print(f\"Fetching exchange rate for {country_name}...\")\n",
        "    rate = get_exchange_rate_from_duckduckgo(country_name)\n",
        "    exchange_rates.append({'Country': country_name, 'Exchange Rate': rate})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 6: Save the Exchange Rates:**\n",
        "*  Store the results in a new CSV file named **exchange_rates_duckduckgo.csv.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved exchange rates to exchange_rates_duckduckgo.csv\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Save the results to a new CSV file\n",
        "df_exchange_rates = pd.DataFrame(exchange_rates)\n",
        "output_file = 'exchange_rates_duckduckgo.csv'\n",
        "df_exchange_rates.to_csv(output_file, index=False)\n",
        "print(f\"Saved exchange rates to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 7: Close Selenium:**\n",
        "*  Shut down the WebDriver after completing the scraping task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Close the Selenium WebDriver\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Complete Script**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching exchange rate for Australia...\n",
            "Fetching exchange rate for Brasil...\n",
            "Failed to get exchange rate for Brasil: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"input[aria-label=\"Currency value in USD\"]\"}\n",
            "  (Session info: chrome=132.0.6834.110); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
            "Stacktrace:\n",
            "0   chromedriver                        0x00000001044b27b8 cxxbridge1$str$ptr + 2598452\n",
            "1   chromedriver                        0x00000001044aaff8 cxxbridge1$str$ptr + 2567796\n",
            "2   chromedriver                        0x000000010404bf0c cxxbridge1$string$len + 88260\n",
            "3   chromedriver                        0x0000000104091000 cxxbridge1$string$len + 371128\n",
            "4   chromedriver                        0x00000001040cb148 cxxbridge1$string$len + 609024\n",
            "5   chromedriver                        0x0000000104084e1c cxxbridge1$string$len + 321492\n",
            "6   chromedriver                        0x0000000104085a64 cxxbridge1$string$len + 324636\n",
            "7   chromedriver                        0x000000010447d6d4 cxxbridge1$str$ptr + 2381136\n",
            "8   chromedriver                        0x00000001044809f4 cxxbridge1$str$ptr + 2394224\n",
            "9   chromedriver                        0x000000010446403c cxxbridge1$str$ptr + 2277048\n",
            "10  chromedriver                        0x00000001044812b4 cxxbridge1$str$ptr + 2396464\n",
            "11  chromedriver                        0x0000000104455c04 cxxbridge1$str$ptr + 2218624\n",
            "12  chromedriver                        0x000000010449bd60 cxxbridge1$str$ptr + 2505692\n",
            "13  chromedriver                        0x000000010449bedc cxxbridge1$str$ptr + 2506072\n",
            "14  chromedriver                        0x00000001044aac6c cxxbridge1$str$ptr + 2566888\n",
            "15  libsystem_pthread.dylib             0x0000000184c2df94 _pthread_start + 136\n",
            "16  libsystem_pthread.dylib             0x0000000184c28d34 thread_start + 8\n",
            "\n",
            "Saved exchange rates to exchange_rates_duckduckgo.csv\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "\n",
        "# Step 1: Load country data from the CSV file\n",
        "csv_file = 'worldwide_latte_prices.csv'  # Replace with your CSV file name\n",
        "countries = pd.read_csv(csv_file)\n",
        "\n",
        "\n",
        "# Step 2: Set up Selenium WebDriver\n",
        "driver = webdriver.Chrome()  # Ensure ChromeDriver is properly set up\n",
        "\n",
        "# Define a function to fetch exchange rate using DuckDuckGo\n",
        "def get_exchange_rate_from_duckduckgo(country_name):\n",
        "    try:\n",
        "        # Open DuckDuckGo and search for the exchange rate\n",
        "        driver.get(\"https://duckduckgo.com/\")\n",
        "        search_box = driver.find_element(By.NAME, \"q\")\n",
        "        search_box.clear()\n",
        "        search_box.send_keys(f\"{country_name} currency to USD\")\n",
        "        search_box.send_keys(Keys.RETURN)\n",
        "\n",
        "        # Wait for results to load\n",
        "        time.sleep(3)\n",
        "\n",
        "        # Locate the input field containing the exchange rate\n",
        "        rate_element = driver.find_element(By.CSS_SELECTOR, 'input[aria-label=\"Currency value in USD\"]')  # Adjusted selector\n",
        "        exchange_rate = rate_element.get_attribute(\"value\")  # Extract the value from the input field\n",
        "        return exchange_rate\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to get exchange rate for {country_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Step 3: Loop through each country and fetch exchange rates\n",
        "exchange_rates = []\n",
        "for _, row in countries.iterrows():\n",
        "    country_name = row['Country']\n",
        "    print(f\"Fetching exchange rate for {country_name}...\")\n",
        "    rate = get_exchange_rate_from_duckduckgo(country_name)\n",
        "    exchange_rates.append({'Country': country_name, 'Exchange Rate': rate})\n",
        "\n",
        "# Step 4: Save the results to a new CSV file\n",
        "df_exchange_rates = pd.DataFrame(exchange_rates)\n",
        "output_file = 'exchange_rates_duckduckgo.csv'\n",
        "df_exchange_rates.to_csv(output_file, index=False)\n",
        "print(f\"Saved exchange rates to {output_file}\")\n",
        "\n",
        "# Close the Selenium WebDriver\n",
        "driver.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "56tfDxbWVq9b"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
